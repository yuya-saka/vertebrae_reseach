{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "430bdc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "# wandb 共通設定\n",
    "WANDB_PROJECT = \"vertebrae-sampling_axial_learning_1\"\n",
    "wandb.login()                     # API キーは環境変数でも可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0fb57",
   "metadata": {},
   "source": [
    "# 学習モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7de1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ef8b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. データセットクラス (CTDataset)\n",
    "##############################################\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = row[\"FullPath\"]\n",
    "        # CSVの列名が \"Fracture_label\" の場合\n",
    "        # (もし \"Fracture_Label\" や別名であれば修正してください)\n",
    "        label = row[\"Fracture_Label\"]\n",
    "\n",
    "        # ----- 画像読み込み (NIfTI) -----\n",
    "        nifti_obj = nib.load(img_path)\n",
    "        img_arr = nifti_obj.get_fdata()\n",
    "\n",
    "        # 3次元の場合は最初のスライスを使う（軸が違うなら適宜変更）\n",
    "        if len(img_arr.shape) == 3:\n",
    "            img_arr = img_arr[:, :, 0]\n",
    "        elif len(img_arr.shape) != 2:\n",
    "            raise ValueError(f\"Unsupported image shape: {img_arr.shape}\")\n",
    "\n",
    "        # ----- HUウィンドウ (100～2000) 例 -----\n",
    "        img_arr = np.clip(img_arr, 100, 2000)\n",
    "        img_arr = (img_arr - 100) / (2000 - 100)  # 0～1 スケーリング\n",
    "        img_arr = np.uint8(img_arr * 255)\n",
    "\n",
    "        pil_img = Image.fromarray(img_arr).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            pil_img = self.transform(pil_img)\n",
    "\n",
    "        return pil_img, float(label)\n",
    "\n",
    "# 2. モデル定義 (ModifiedResNet)\n",
    "##############################################\n",
    "class ModifiedResNet(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(ModifiedResNet, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # 1ch入力に変更\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # 出力層を差し替え → 1ユニット (Sigmoid)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 4. 検証関数 (evaluate_model)\n",
    "##############################################\n",
    "def evaluate_model(model, val_loader, criterion, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "            outputs = model(images).squeeze()  # shape: (batch,)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "\n",
    "    # Precision-Recall\n",
    "    precision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\n",
    "    prauc = auc(recall, precision)\n",
    "\n",
    "    # F1最大となる閾値を検索\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    best_precision = precision[best_idx]\n",
    "    best_recall = recall[best_idx]\n",
    "\n",
    "    return avg_loss, prauc, best_threshold, best_precision, best_recall\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b48897",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                scheduler=None, num_epochs=20, device=\"cuda\"):\n",
    "    run = wandb.init(project=WANDB_PROJECT, reinit=True,\n",
    "                     config=dict(\n",
    "                         epochs=num_epochs,\n",
    "                         lr=optimizer.param_groups[0][\"lr\"],\n",
    "                         weight_decay=optimizer.param_groups[0][\"weight_decay\"],\n",
    "                         dropout=getattr(model.resnet.fc[0], \"p\", None)\n",
    "                     ))\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)\n",
    "\n",
    "    best_prauc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # ----- Training -----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"[Train] {epoch+1}/{num_epochs}\"):\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # ----- Validation -----\n",
    "        val_loss, val_prauc, th, prec, rec = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        # wandb ログ\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\":   val_loss,\n",
    "            \"val_prauc\":  val_prauc,\n",
    "            \"best_th\":    th,\n",
    "            \"precision\":  prec,\n",
    "            \"recall\":     rec,\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "\n",
    "        # scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        # モデル保存\n",
    "        if val_prauc > best_prauc:\n",
    "            best_prauc = val_prauc\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # 例: 20250414_113045\n",
    "            model_path = f\"best_model_{timestamp}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            wandb.run.summary[\"best_prauc\"] = best_prauc\n",
    "            wandb.run.summary[\"best_epoch\"] = epoch+1\n",
    "            wandb.run.summary[\"saved_model_path\"] = model_path\n",
    "\n",
    "            #使わない\n",
    "            #torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            #wandb.run.summary[\"best_prauc\"] = best_prauc\n",
    "            #wandb.run.summary[\"best_epoch\"] = epoch+1\n",
    "\n",
    "    wandb.finish()\n",
    "    return best_prauc\n",
    "\n",
    "\n",
    "def grid_search(train_loader, val_loader, device=\"cuda\"):\n",
    "    num_epochs_list   = [20, 30]\n",
    "    lr_list           = [1e-5, 3e-5]\n",
    "    weight_decay_list = [1e-3, 1e-2]\n",
    "    dropout_rate_list = [0.3, 0.0]\n",
    "\n",
    "    for (num_epochs, lr, wd, do) in product(num_epochs_list, lr_list, weight_decay_list, dropout_rate_list):\n",
    "        model = ModifiedResNet(dropout_rate=do).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "        best_prauc = train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                                 scheduler=scheduler, num_epochs=num_epochs, device=device)\n",
    "        print(f\"Finished: Ep{num_epochs} LR{lr} WD{wd} DO{do} → PRAUC {best_prauc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0abf73",
   "metadata": {},
   "source": [
    "# sweep_config = {\n",
    "#     \"method\": \"random\",\n",
    "#     \"metric\": {\"name\": \"val_prauc\", \"goal\": \"maximize\"},\n",
    "#     \"parameters\": {\n",
    "#         \"epochs\":       {\"values\": [20, 30]},\n",
    "#         \"lr\":           {\"values\": [1e-5, 3e-5]},\n",
    "#         \"weight_decay\": {\"values\": [1e-3, 1e-2]},\n",
    "#         \"dropout\":      {\"values\": [0.0, 0.3]}\n",
    "#     }\n",
    "# }\n",
    "# sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT)\n",
    "# \n",
    "# def sweep_train():\n",
    "#     # wandb.config からパラメータ取得\n",
    "#     c = wandb.config\n",
    "#     model = ModifiedResNet(dropout_rate=c.dropout).to(device)\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=c.lr, weight_decay=c.weight_decay)\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "#     train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "#                 scheduler=scheduler, num_epochs=c.epochs, device=device)\n",
    "# \n",
    "# wandb.agent(sweep_id, function=sweep_train, count=20)   # 例: 20 試行\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e19b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_csv = \"/mnt/nfs1/home/yamamoto-hiroto/research/vertebrae/Sakaguchi_file/slice_train_sampling/axial/sampling_labels_axial_2.csv\"\n",
    "val_csv   = \"/mnt/nfs1/home/yamamoto-hiroto/research/vertebrae/Sakaguchi_file/slice_val/axial/val_labels_axial.csv\"\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = CTDataset(train_csv, transform=transform_train)\n",
    "val_dataset   = CTDataset(val_csv,   transform=transform_val)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=4)\n",
    "val_loader    = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ---- 実行 ----\n",
    "grid_search(train_loader, val_loader, device=device)\n",
    "# あるいは wandb Sweep を回す場合はセル 6‑B を実行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
