{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8æ¤ä½“éª¨æŠ˜æ¤œå‡ºãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯`train_yolo.py`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å¯¾è©±çš„ã«å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚\n",
    "\n",
    "## æ¦‚è¦\n",
    "- YOLOv8ã‚’ä½¿ç”¨ã—ãŸæ¤ä½“éª¨æŠ˜æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "- åŒ»ç™‚ç”»åƒã«ç‰¹åŒ–ã—ãŸè¨­å®š\n",
    "- Weights & Biasesã«ã‚ˆã‚‹å®Ÿé¨“ç®¡ç†\n",
    "- ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka\n",
      "CUDAåˆ©ç”¨å¯èƒ½: True\n",
      "CUDA ãƒ‡ãƒã‚¤ã‚¹: NVIDIA RTX A6000\n",
      "CUDA ãƒ¡ãƒ¢ãƒª: 47.5 GB\n"
     ]
    }
   ],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "project_root = Path(os.getcwd()).parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# train_yolo.pyã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from train_yolo import VertebralFractureYOLO\n",
    "\n",
    "print(f\"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {project_root}\")\n",
    "print(f\"CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA ãƒ‡ãƒã‚¤ã‚¹: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture/configs/vertebrae_fracture.yaml\n",
      "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: True\n",
      "\n",
      "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹:\n",
      "  path: /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture\n",
      "  train: train/images\n",
      "  val: val/images\n",
      "  test: test/images\n",
      "  nc: 1\n",
      "  names: ['fracture']\n"
     ]
    }
   ],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
    "config_path = project_root / \"Sakaguchi_file/YOLO_datasets/vertebrae_fracture/configs/vertebrae_fracture.yaml\"\n",
    "\n",
    "print(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {config_path}\")\n",
    "print(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {config_path.exists()}\")\n",
    "\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"\\nè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLOãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 18:28:16,517 - INFO - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture/configs/vertebrae_fracture.yaml\n",
      "2025-07-17 18:28:16,621 - INFO - YOLOv8ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–: yolov8m.pt\n",
      "2025-07-17 18:28:16,622 - INFO - å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: runs/train/20250717_182816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: yolov8m.pt\n",
      "ã‚¨ãƒãƒƒã‚¯æ•°: 50\n",
      "ãƒãƒƒãƒã‚µã‚¤ã‚º: 16\n",
      "Weights & Biasesä½¿ç”¨: True\n",
      "\n",
      "âœ… YOLOãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–å®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š\n",
    "MODEL_SIZE = 'yolov8m.pt'  # yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "USE_WANDB = True  # Weights & Biasesã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹\n",
    "\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: {MODEL_SIZE}\")\n",
    "print(f\"ã‚¨ãƒãƒƒã‚¯æ•°: {EPOCHS}\")\n",
    "print(f\"ãƒãƒƒãƒã‚µã‚¤ã‚º: {BATCH_SIZE}\")\n",
    "print(f\"Weights & Biasesä½¿ç”¨: {USE_WANDB}\")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–\n",
    "trainer = VertebralFractureYOLO(\n",
    "    config_path=str(config_path),\n",
    "    model_size=MODEL_SIZE\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… YOLOãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weights & Biasesã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# wandBã§ã®å­¦ç¿’æ›²ç·šè¡¨ç¤ºè¨­å®šï¼ˆS_model_learningæº–æ‹ ï¼‰\nprint(\"ğŸ“Š å­¦ç¿’æ›²ç·šã¯wandBãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèªã—ã¾ã™\")\nprint(\"ğŸ’¡ ä»¥ä¸‹ã®æ‰‹é †ã§å­¦ç¿’æ›²ç·šã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–ã§ãã¾ã™ï¼š\")\nprint()\nprint(\"1. ğŸŒ https://wandb.ai ã«ã‚¢ã‚¯ã‚»ã‚¹\")\nprint(\"2. ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ 'vertebrae-fracture-axial-1' ã‚’é¸æŠ\")\nprint(\"3. ğŸ“ˆ å®Ÿè¡Œä¸­ã®å®Ÿé¨“ã‚’ã‚¯ãƒªãƒƒã‚¯\")\nprint(\"4. ğŸ“Š 'Charts' ã‚¿ãƒ–ã§å­¦ç¿’æ›²ç·šã‚’ç¢ºèª\")\nprint()\nprint(\"ğŸ“ˆ ç›£è¦–ã™ã¹ãä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹:\")\nprint(\"   â€¢ train/box_loss - å­¦ç¿’ç”¨Box Loss\")\nprint(\"   â€¢ val/box_loss - æ¤œè¨¼ç”¨Box Loss\")\nprint(\"   â€¢ train/cls_loss - å­¦ç¿’ç”¨åˆ†é¡Loss\")\nprint(\"   â€¢ val/cls_loss - æ¤œè¨¼ç”¨åˆ†é¡Loss\")\nprint(\"   â€¢ metrics/mAP50(B) - mAP@0.5\")\nprint(\"   â€¢ metrics/mAP50-95(B) - mAP@0.5:0.95\")\nprint(\"   â€¢ metrics/precision(B) - ç²¾åº¦\")\nprint(\"   â€¢ metrics/recall(B) - å†ç¾ç‡\")\nprint()\nprint(\"ğŸ’¡ å­¦ç¿’é–‹å§‹å¾Œã€wandBãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§å­¦ç¿’æ›²ç·šãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ›´æ–°ã•ã‚Œã¾ã™\")\nprint(\"âœ… wandBå­¦ç¿’æ›²ç·šç›£è¦–ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n",
      "  data: /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture/configs/vertebrae_fracture.yaml\n",
      "  epochs: 50\n",
      "  batch: 16\n",
      "  imgsz: 640\n",
      "  device: cuda\n",
      "  lr0: 0.01\n",
      "  lrf: 0.01\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  hsv_h: 0.015\n",
      "  hsv_s: 0.3\n",
      "  hsv_v: 0.3\n",
      "  degrees: 20\n",
      "  translate: 0.1\n",
      "  scale: 0.2\n",
      "  shear: 0.1\n",
      "  perspective: 0.0\n",
      "  flipud: 0.0\n",
      "  fliplr: 0.5\n",
      "  mosaic: 0.8\n",
      "  mixup: 0.1\n",
      "  copy_paste: 0.1\n",
      "  dropout: 0.0\n",
      "  label_smoothing: 0.0\n",
      "  val: True\n",
      "  save_period: 10\n",
      "  save_json: True\n",
      "  project: runs/train\n",
      "  name: 20250717_182816\n",
      "  patience: 30\n",
      "  workers: 4\n",
      "  seed: 42\n",
      "  deterministic: True\n",
      "  single_cls: True\n",
      "  rect: True\n",
      "  cos_lr: True\n",
      "  close_mosaic: 10\n",
      "  resume: False\n",
      "  amp: True\n",
      "  fraction: 1.0\n",
      "  profile: False\n",
      "  freeze: None\n",
      "  multi_scale: True\n",
      "  overlap_mask: True\n",
      "  mask_ratio: 4\n",
      "  box: 7.5\n",
      "  cls: 0.5\n",
      "  dfl: 1.5\n",
      "  pose: 12.0\n",
      "  kobj: 2.0\n",
      "  nbs: 64\n",
      "  optimizer: auto\n"
     ]
    }
   ],
   "source": [
    "# å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦è¡¨ç¤º\n",
    "params = trainer.get_training_params()\n",
    "params['epochs'] = EPOCHS\n",
    "params['batch'] = BATCH_SIZE\n",
    "\n",
    "print(\"å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 æœ€çµ‚çš„ãªå­¦ç¿’æ›²ç·šã®è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# wandBã§ã®å­¦ç¿’çµæœç¢ºèª\nprint(\"ğŸ“Š å­¦ç¿’çµæœã®ç¢ºèª\")\nprint(\"=\" * 50)\n\n# å­¦ç¿’å®Œäº†ã®ç¢ºèª\nif 'results' in locals():\n    print(\"âœ… å­¦ç¿’ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ\")\n    \n    # å­¦ç¿’ã‚µãƒãƒªãƒ¼ã®ä¿å­˜\n    trainer.save_training_summary(results)\n    print(\"ğŸ“„ å­¦ç¿’ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n    \n    # wandBã§ã®ç¢ºèªã‚’ä¿ƒã™\n    print(\"\\\\nğŸ“Š è©³ç´°ãªå­¦ç¿’æ›²ç·šã¨çµæœã®ç¢ºèª:\")\n    print(\"ğŸŒ https://wandb.ai ã«ã‚¢ã‚¯ã‚»ã‚¹\")\n    print(\"ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: vertebrae-fracture-axial-1\")\n    print(\"ğŸ“ˆ ä»¥ä¸‹ã®å­¦ç¿’æ›²ç·šã‚’ç¢ºèªã—ã¦ãã ã•ã„:\")\n    print(\"   â€¢ Loss curves (train/val)\")\n    print(\"   â€¢ mAP curves\")\n    print(\"   â€¢ Precision/Recall curves\")\n    print(\"   â€¢ Learning rate schedule\")\n    print(\"   â€¢ Model predictions\")\n    \n    # æœ€çµ‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç°¡æ˜“è¡¨ç¤º\n    if hasattr(results, 'results_dict'):\n        print(\"\\\\nğŸ“ˆ æœ€çµ‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæ¦‚è¦ï¼‰:\")\n        metrics = results.results_dict\n        for key, value in metrics.items():\n            if 'mAP' in key or 'precision' in key or 'recall' in key:\n                print(f\"   {key}: {value:.4f}\")\n    \n    # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª\n    best_model_path = trainer.output_dir / \"weights\" / \"best.pt\"\n    last_model_path = trainer.output_dir / \"weights\" / \"last.pt\"\n    \n    print(f\"\\\\nğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«:\")\n    if best_model_path.exists():\n        print(f\"   ğŸ† Best model: {best_model_path}\")\n    if last_model_path.exists():\n        print(f\"   ğŸ“ Last model: {last_model_path}\")\n        \n    # YOLOv8ãŒè‡ªå‹•ç”Ÿæˆã—ãŸçµæœç”»åƒã®ç¢ºèª\n    results_png = trainer.output_dir / \"results.png\"\n    if results_png.exists():\n        print(f\"\\\\nğŸ“Š YOLOv8è‡ªå‹•ç”Ÿæˆå­¦ç¿’æ›²ç·š: {results_png}\")\n        print(\"   (ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥é–‹ã„ã¦ç¢ºèªã—ã¦ãã ã•ã„)\")\n    \n    print(\"\\\\nğŸ’¡ å­¦ç¿’æ›²ç·šã®è©³ç´°åˆ†æã¯wandBãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§è¡Œã£ã¦ãã ã•ã„\")\n    \nelse:\n    print(\"âš ï¸ å­¦ç¿’çµæœãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n    print(\"å­¦ç¿’ã‚’å®Œäº†ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 18:13:56,995 - INFO - YOLOv8ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å­¦ç¿’é–‹å§‹æ™‚åˆ»: 2025-07-17 18:13:56\n",
      "==================================================\n",
      "WARNING âš ï¸ 'label_smoothing' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.167 ğŸš€ Python-3.12.8 torch-2.4.0+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture/configs/vertebrae_fracture.yaml, degrees=20, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.3, hsv_v=0.3, imgsz=640, int8=False, iou=0.7, keras=False, kobj=2.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.8, multi_scale=True, name=20250717_1813002, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train/20250717_1813002, save_frames=False, save_json=True, save_period=10, save_txt=False, scale=0.2, seed=42, shear=0.1, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding class names with single class.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 86.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.2Â±0.0 ms, read: 86.3Â±25.7 MB/s, size: 27.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture/train/labels.cache... 37367 images, 33979 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37367/37367 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.0 ms, read: 88.8Â±8.4 MB/s, size: 31.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/nfs1/home/yamamoto-hiroto/research/vertebrae_saka/Sakaguchi_file/YOLO_datasets/vertebrae_fracture/val/labels.cache... 10843 images, 10357 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10843/10843 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train/20250717_1813002/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/20250717_1813002\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      13.9G     0.4534      8.413     0.4053          0        544:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 892/2336 [02:42<04:23,  5.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# å­¦ç¿’å®Ÿè¡Œ\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# å­¦ç¿’å®Œäº†\u001b[39;00m\n\u001b[32m     11\u001b[39m     end_time = datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/vertebrae_saka/Sakaguchi_file/YOLO_training/train_yolo.py:174\u001b[39m, in \u001b[36mVertebralFractureYOLO.train\u001b[39m\u001b[34m(self, epochs, batch_size)\u001b[39m\n\u001b[32m    170\u001b[39m params[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m] = batch_size\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# å­¦ç¿’å®Ÿè¡Œ\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33må­¦ç¿’å®Œäº†\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/vertebrae_saka/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:799\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    798\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/vertebrae_saka/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/vertebrae_saka/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:419\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m     last_opt_step = ni\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/vertebrae_saka/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:646\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ema:\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mema\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/vertebrae_saka/.venv/lib/python3.12/site-packages/ultralytics/utils/torch_utils.py:692\u001b[39m, in \u001b[36mModelEMA.update\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m v.dtype.is_floating_point:  \u001b[38;5;66;03m# true for FP16 and FP32\u001b[39;00m\n\u001b[32m    691\u001b[39m     v *= d\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m     v += (\u001b[32m1\u001b[39m - d) * msd[k].detach()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# å­¦ç¿’é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²\n",
    "start_time = datetime.now()\n",
    "print(f\"å­¦ç¿’é–‹å§‹æ™‚åˆ»: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å­¦ç¿’å®Ÿè¡Œ\n",
    "try:\n",
    "    results = trainer.train(epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # å­¦ç¿’å®Œäº†\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"âœ… å­¦ç¿’å®Œäº†!\")\n",
    "    print(f\"å­¦ç¿’æ™‚é–“: {duration}\")\n",
    "    print(f\"å­¦ç¿’å®Œäº†æ™‚åˆ»: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å­¦ç¿’çµæœã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’çµæœã®è¡¨ç¤º\n",
    "if 'results' in locals():\n",
    "    print(\"å­¦ç¿’çµæœ:\")\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        for key, value in results.results_dict.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # å­¦ç¿’ã‚µãƒãƒªãƒ¼ã®ä¿å­˜\n",
    "    trainer.save_training_summary(results)\n",
    "    print(\"\\nâœ… å­¦ç¿’ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "else:\n",
    "    print(\"âš ï¸ å­¦ç¿’çµæœãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡\n",
    "try:\n",
    "    print(\"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡ã‚’å®Ÿè¡Œä¸­...\")\n",
    "    val_results = trainer.evaluate(data_split='val')\n",
    "    \n",
    "    print(\"\\nâœ… è©•ä¾¡å®Œäº†\")\n",
    "    print(f\"è©•ä¾¡çµæœ: {val_results}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ã‚µãƒ³ãƒ—ãƒ«æ¨è«–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ\n",
    "# æ¨è«–ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
    "sample_image_path = None  # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆç”»åƒãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
    "\n",
    "if sample_image_path and Path(sample_image_path).exists():\n",
    "    try:\n",
    "        print(f\"ã‚µãƒ³ãƒ—ãƒ«æ¨è«–: {sample_image_path}\")\n",
    "        inference_results = trainer.predict_sample(sample_image_path, conf_threshold=0.25)\n",
    "        print(f\"æ¨è«–çµæœ: {inference_results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ ã‚µãƒ³ãƒ—ãƒ«æ¨è«–ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç”»åƒãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ãƒ¢ãƒ‡ãƒ«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã‚’ONNXå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "export_format = 'onnx'  # 'onnx', 'torchscript', 'tensorrt'\n",
    "\n",
    "try:\n",
    "    print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’{export_format}å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...\")\n",
    "    exported_model = trainer.export_model(format=export_format)\n",
    "    print(f\"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {exported_model}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. å¾Œå‡¦ç†ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights & Biasesã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ‚äº†\n",
    "if USE_WANDB:\n",
    "    try:\n",
    "        import wandb\n",
    "        wandb.finish()\n",
    "        print(\"âœ… Weights & Biases ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Weights & Biases ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¡¨ç¤º\n",
    "print(f\"\\nğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {trainer.output_dir}\")\n",
    "print(f\"ğŸ“ å­¦ç¿’çµæœã®ä¿å­˜å ´æ‰€: {trainer.output_dir}\")\n",
    "\n",
    "# å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
    "print(\"\\nğŸ‰ å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertebrae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}